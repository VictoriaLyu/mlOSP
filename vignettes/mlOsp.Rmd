---
title: "Machine Learning for Optimal Stopping Problems with mlOSP"
author: "Mike Ludkovski"
date: "July 26, 2018"
output: 
  pdf_document: 
    number_sections: yes
fig_width:  10
fig_height:  6
fig_caption: TRUE
toc: TRUE
lof: TRUE
bibliography: rmcBook.bib
citation_package: natbib
keep_tex: TRUE
keep_md: TRUE
latex_engine: pdflatex
vignette: >
  %\VignetteIndexEntry{Machine Learning for Optimal Stopping Problems with mlOSP}
  \usepackage[utf8]{inputenc}
  %\VignetteEngine{knitr::rmarkdown}
header-includes: 
    \usepackage{fancyhdr}
    \usepackage{algorithm2e}
    \usepackage{bm}
    \pagestyle{fancy}
    \fancyhead[CO,CE]{}
    \fancyfoot[CO,CE]{Mike Ludkovski \thedate}
    \fancyfoot[LE,RO]{\thepage}
abstract: This is a Mike test . . . 
---

```{r setup, include=FALSE}
 knitr::opts_chunk$set(echo = TRUE, fig.path='figures/', dev=c('png', 'pdf'), dpi=100, fig.width=6.4, fig.height=3.6,cache=TRUE,warning=FALSE,message=FALSE)
```

# Introduction

We introduce \code{mlOSP}, a computational template for Machine Learning for Optimal Stopping Problems. The template is implemented in the `R` statistical environment and publicly available via a `GitHub` repository. Our template nests much of the existing literature on regression-based approaches to optimal stopping and through a unified numerical implementation allows for transparent and verifiable benchmarking of extant algorithms. Moreover, the modularity of the mlOSP framework offers abundant opportunities for new versions of RMC algorithms, with numerous ideas already implemented in the `R` package and presented below.


## Simulation Based Optimal Stopping and Beyond

Numerical resolution of optimal stopping problems has been an active area of research for more than 2 decades. Originally investigated in the context of American Option pricing, it has since metamorphosed into a field unto itself, with numerous wide-ranging applications and dozens of proposed approaches.

A major strand, which is increasingly dominating the subject, are simulation-based methods that apply the Monte Carlo paradigm to Optimal Stopping. With its roots in 1990s, this framework remains without an agreed-upon name; we shall refer to it as Regression Monte Carlo (RMC). The main feature of RMC is its marriage of a probabilistic approach, namely direct reliance on the underlying stochastic state dynamics as part of the simulations, and statistical tools for approximating the quantities of interest, primarily the value and/or continuation functions. This combination of simulation and statistics brings scalability, flexibility in terms of underlying model assumptions and a vast arsenal of potential implementations. These benefits have translated into excellent performance which has made RMC popular both in the academic and practitioner (quantitative finance) communities. Indeed, in the opinion of the author, these developments can claim to be the most successful numerical strategy that emerged from Financial Mathematics. Dating back only about 20 years, they have now percolated down into standard Masters-level curriculum, and are increasingly utilized in cognate engineering and mathematical sciences domains. 

Despite hundreds of journal publications addressing various variants of RMC, there remains a dearth of user-friendly benchmarks or unified overviews of the algorithms. In particular, to the author's knowledge, there is no `R` (or other free programming languages such as `Python`) package for RMC (some small stand-alone versions are XXX). One reason for this gap is the narrow focus of many research articles that tend to explore one small aspect of RMC and then illustrate their contributions on a small-scale, idiosyncratic example. 

In the present article, I offer an algorithmic template for RMC, coupled with its implementation within R. This endevour is meant to be an ongoing project, offering one way to centralize and standardize RMC approaches, as they are proposed. In particular, the associated **mlOSP** library is currently in its Version 1.0 incarnation, with further (hopefully regular) updates to be fully expected.

## Contributions 

`mlOSP` offers a unified description of RMC via the underlying statistical concepts. Hence, we describe a *generic* RMC template that emphasizes the building blocks, rather than specific approaches. This perspective therefore aims to *nest* as many of existing works as possible, shedding light on the differences and the similarities between the numerous proposals. Thus, the template itself should be viewed as a contribution, giving a new take on (quite) old ideas, and tying disparate extant presentations. 

A key motivation for building the template was to create transparent and verifiable benchmarks for RMC algorithms. While many published works contain detailed comparisons between the proposed RMC version and competing approaches, these comparisons are necessarily limited in scope and are often very difficult to reproduce. There are many challenges to creating a good benchmark:

* RMC algorithms tend to have a slew of tuning parameters that might significantly affect performance (from number of simulations, to the precise choice of the regression specification);

* One must define a complete problem instance, i.e. the payoff function, state dynamics, etc. While some test cases (see Model A and B below) have appeared repeatedly, there is no agreed upon benchmark portfolio to apply. Many algorithms are of course very sensitive to the dimensionality of the problem, the geometry of the value function, etc.

* There are multiple metrics one could utilize to compare solution quantity across algorithms, including accuracy at a fixed simulation budget, accuracy at a fixed computation time, running time at fixed budget. Again, there is no single consistent set of such criteria to fall back upon;

* The above metrics are heavily affected by the particular implementation, including the lower-level programming environment (say R vs C++), the machine running the benchmark, the operating system, etc.

Due to all the above, the only way to create a "level playing field" for different algorithms is to bring them all under a single roof, coded side-by-side within a transparent environment. This is precisely what is achieved in `mlOSP`. In the companion software appendix, we provide the RMarkdown code that can be downloaded and run by any reader or end-user to fully reproduce our results, figures and tables. To our knowledge, this is the most comprehensive verifiable set of RMC benchmarks (some similar attempts are in StochOpt and Langrene). The R code also makes completely transparent our chosen set of fully specified problem instances, which would be useful for other researchers in the future.

To specify `mlOSP', we utilize as much as possible the language of statistics (in contrast to the language of finance, or of probability). In particular, we attempt to place RMC in the context of modern machine/statistical learning, highlighting such aspects as Design of Experiments, Simulation Device, and Sequential Learning. Through this angle, we naturally connect RMC with numerous alternative tools, twists, and extensions. In particular, within the `mlOSP` template we propose and implement several new variants:

* Adaptive (ie cross-validated) kernel regression using npreg and kernlab and svm

* Varying the design size $N$ across time-steps

* Multiple versions of generating space-filling experimental designs

* A variety of sequential design heuristics, including with adaptive batching

* hetGP/hetTP regression

* dynamic look-ahead simulators based on Egloff


## Organization

The article is structured as an extended vignette and consists of three parts. The first part lays out the RMC template which underlies the **mlOSP** library. The template emphasizes the three pieces of RMC framework: stochastic simulation, experimental design, and statistical approximation. These pieces are modularized and can be fully mixed-and-matched within the core backward dynamic programming loop driving the algorithms. Section XXX briefly summarizes the variants of each module that have been implemented, and includes references to the original articles where these were proposed. For example, we provide more than 10 different methods for the regression module, ranging from kernel regression to piecewise linear regression to Gaussian process regression.

The second part serves as a "User Guide" to `mlOSP` and illustrates how the template is implemented in the library. For ease of use, we provide about half-dozen top-level functions, whose usage is illustrated via code listings and the respective R output. Simultaneously with illustrating *how* to use **mlOSP**, we also define several instances of OSP, including examples of Bermudan options in 1-, 2-, 3-, and 5-dimensions. In Section XX we proceed to benchmark, running 7 mlOSP solvers on 6 OSP instances. Beyond providing an apples-to-apples comparison of different solvers, we also showcase in more depth the impact of (i) simulation budget; (ii) regression specification; (iii) experimental design specification; (iv) simulator type. All these benchmarks are organized as a  companion RMarkdown document that is posted on GitHub, enabling full reproduction by any reader who downloads the **mlOSP** package. 

By providing fully reproducible results on these instances, we hope to create a preliminary set of simple benchmarks that allow for a transparent, apples-to-apples comparison of different methods. As we discuss below, the numerous nuances that inevitably crop up when implementing RMC, frequently make such comparisons fraught, leading to a lack of consensus on what strategies are more efficient. [move later]

Finally, the third part of the paper in Section XX discusses extensions of our template. Indeed, a major goal is to build an interlocking collection of computational tools for decision-making under uncertainty. To this end, the mlOSP template admits generalizations in several directions. Section 5.1 discusses and showcases one such extension to handle multiple-stopping problems, illustrated with Bermudan Swing options. In a different vein, Section 5.2 goes through the steps to define a new OSP instance.  The **mlOSP** library is meant to be extensible in the sense of offering a simple interface to define new OSP instances.  These features of **mlOSP** are illustrated at the end of the "User Guide" where we take examples from a couple of very recent papers and show how they can be embedded into the **mlOSP** template to facilitate comparison with existing ideas.



# Optimal Stopping and RMC

 An optimal stopping problem is described through two main ingredients: the state process and the reward function. We shall use $X$ to denote the state process, assumed to be a stochastic process indexed generically by the time index $t$. The reward function is $h(t,x)$ where the notation emphasizes the common possibility of the reward depending on time, e.g. due to discounting.
 
We seek the rule $\tau$,   a *stopping time* to maximize expected reward:
 \begin{align}\E[ h(\tau,X_\tau) ] \rightarrow \max! \end{align}
To this end, we wish to evaluate the value function
\begin{align}
V(t,x) = \sup_{\tau \in \cal{S}} \mathbb{E}[ h(\tau, X_\tau) | X_t = x ]
\end{align}

The state $(X_t)$ is typically assumed to satisfy a Stochastic Differential Equation of  Ito type,
$$  dX_t = \mu(X_t) \, dt + \sigma(X_t)\, dW_t,$$
where $(W_t)$ is a (multi-dimensional) Brownian motion. 

To understand optimal stopping, it is most intuitive to think of it as a dynamic decision making. At each exercise step, the controller must decide whether to stop (0) or continue (1), which within a Markovian structure is encoded via the action map $A_t(x)  \in \{ 0,1 \}$. This action map gives rise to the stopping region
$$ {\cal S}_t = \{ x : A_t(x) = 0\} $$ 
where the decision is to stop and in parallel defines the corresponding $\tau = \min \{ t: A(X_t) = 0 \}$
Hence, solving an OSP is equivalent to classifying each $x$ into ${\cal S}_t$ or its complement the continuation set. The respective objective function is the expected reward:
$$ \widehat{V}(t,x)[A] := \mathbb{E}[ h(\tau_A, X^x_{\tau_A})].$$

The RMC construction relies on recursively constructing $A_t$ based on $(A_s : s > t)$. This is achieved by rephrasing
$$ A_t(x) = 1 \quad \Leftrightarrow \quad \mathbb{E}[ h(\tau_{A_{t+1}}, X^x_{\tau_{A_{t+1}}})] > h(t,x) $$, i.e. one should contain if the expected reward-to-go dominates the immediate payoff. The Dynamic Programming Principle implies that the right-hand-side can be expressed as the conditional expectation of $V(t+1, X^x_{t+1})$, henceforth termed the continuation value
$$ q(t,x) = \mathbb{E}[ V(t+1, X^x_{t+1}) | X_t =x]. $$

This construction yields the following loop:
1. Set $V(T,x)=h(T,x)$

2. For $t=T-1,...,1$

i) Learn the conditional expectation $\hat{q}(t,\cdot) = \hat{E}[ \hat{V}(t+1, \cdot) | X_t = x]$

ii) Set $\hat{A}_t(x) = \{ 1 : \hat{q}(t,x) > h(t,x) \}$

iii) Set $\hat{V}(t,x) = \max ( \hat{q}(t,x), h(t,x))$

3. Run out-of-sample $$ \hat{V}(0,x_0) = \frac{1}{N'} \sum_{n'=1}^{N'} h(\tau_{\hat{A}(0)}, X_\tau)$$

The key step requiring numeric approximation is 2i. In the RMC paradigm it is handled by re-interpreting conditional expectation as the mean response within a stochastic input-output model. Thus, given an input $x$, there is a generative model which is not directly known but accessible through a pathwise reward simulator. The aim is then to predict the mean output of this simulator for an arbitrary $x$. Practically, this is done by running some simulations and then utilizing a statistical model to capture the observed input-output relationship.  This statistical learning task can be broken further down into three sub-problems:

1. Defining the stochastic simulator

2. Defining the simulation design

3. Defining the regression step

Recasting in the machine learning terminology, we need to define a simulator that accept a value $x$ (the initial state at time $t$) and return $Y$ which is a random realization of the pathwise reward starting at $(t,x)$. We then need to decide which collection of $x$'s should be applied as a training set. After selecting such experimental design of size $N$, $x^{1:N}$, we collect the $y^{1:N} = Y(x^{1:N})$ and reconstruct the model
$$ Y(x) = f(x) + \epsilon(x), \qquad \mathbb{E}[ \epsilon(x)] = 0, \mathbb{V}ar(\epsilon(x)) = \sigma^2(x)$$
where $f(x) \equiv \hat{q}(t,x)$ and the model is labeled as $\hat{E}_t$ to reflect the fact that it approximates the conditional expectation. 
 
We now make a few remarks:

* The procedure is recursive, necessarily the simulator at step $t$ is linked to the previous simulators/emulators at steps $s > t$. Therefore, errors will tend to back-propagate. 

* There is no ``data'' per se, the controller is fully in charge of selecting what simulations to run. Judicious choice of how to do so is our primary criterion of numerical efficiency. Deciding how to train $\hat{q}$ is a key step in RMC.

* In classical ML tasks, there is a well-defined loss functions that quantifies the quality of the constructed approximation. In OSP, this loss function is highly implicit; ultimately we judge algorithm performance in terms of the final $\hat{V}(0,x_0)$ (higher is better). Thus, one must construct heuristics to translate this into the loss function for the local learning task.

* RMC is a **sequence** of tasks, indexed by $t$. While the tasks are inter-related, since they are solved one-by-one, there is a large scope for modularization, adaptation, etc to be utilized.

* The stochasticity in RMC comes from using the pathwise simulator and is ultimately based on the random shocks driving the evolution of $(X_t)$. Thus, the stochasticity is deeply imbedded in the problem. Because it is so intrinsic, $\epsilon(x)$ must be understood not as observation noise but rather simulation noise. In particular, its statistical properties tend to be quite complex and non-Gaussian.

* The basic loop makes it clear that like in standard regression, there ought to be a training set (used in the backward iteration) and a test set, used for estimating $\hat{V}(0,x_0)$. Because the latter is essentially a plain MC estimate of expected reward given the specific stopping rule $\tau(\hat{A})$, ie. of $\mathbb{E}[ h(\tau_{\hat{A}(0)}, X_{\tau_{\hat{A}(0)}})]$, modulo MC error (captured by the LLN and CLT) it will yield a lower bound on the true maximum expected reward. In contrast, any attempt to use the training data to estimate expected rewards cannot come with any reasonably upper/lower bound guarantees. 

## Dynamic Emulation Template

\begin{algorithm}[!ht]
\SetAlgoLined
\KwData{$K=T/\Delta t$ (time steps), $(N_k)$ (simulation budgets per step) }
Generate design $\mathcal{D}_{K-1} := (\bm{X}_{K-1}^{(K)})$ of size $N_{K-1}$ \\
Generate one-step paths $X_{K-1}^{n,(K-1)} \mapsto X_{K}^{n,(K-1)}$ for $n=1,\ldots,N_{K-1}$ \\
Terminal condition:   $v_{K}^n \leftarrow h(T,X_{K}^{n,(K)})$ for $n=1,\ldots, N_{K-1}$\\
\For{$ k=K - 1, \ldots, 1$ }{
Fit $\hat{q}(k,\cdot) \leftarrow \arg \min_{h_k \in \mathcal{H}_k} \sum_{n=1}^{N_k} |h_{k}(X_{k}^{n,(k)}) - v_{k+1}^n |^2$  \\
Generate design $\mathcal{D}_{k-1} := (\bm{X}_{k-1}^{(k-1)})$ of size $N_{k-1}$  \\
Generate $w$-step paths $X_{k-1}^{n,(k-1)} \mapsto X_{s}^{n,(k-1)}$ for $n=1,\ldots,N_{k-1}$, $s=k,\ldots,k+w-1$\\

\For{$n=1,\ldots,N_{k-1}$  }  {
  Save $a_k \leftarrow \arg \max$ \\
  Need notation for pathwise payoff
	$v^n_{k} \leftarrow  \max \left(h(k\Delta t, X_{k-1}^{n,(K)}), \hat{q}(k, X_k^{n,(k-1)}) 	\right)$ 
}

}
Generate $N'$ paths $X'_{0:K}$
return $\{ \hat{q}(k,\cdot) \}_{k=1}^{K-1}$\\
\caption{Dynamic Emulation Algorithm (DEA) - $\mathcal{O}(KN)$}
\label{algo_Generalized}
\end{algorithm}

The two flexible steps is generating $\mathcal{D}_{k}$ and the approximation $\hat{q}$. Note that the latter is a statistical model; it is viewed as an object (rather than say a vector of numbers) and passed as a "function pointer" to the pathwise reward simulator in subsequent steps. The latter simulator iin turn applies a **predict** method to the fitted model, asking it to furnish a predicted expected reward at arbitrary $(t,x)$. Observe that in the LS variant ($w(k) = K-k$), the pathwise simulator is *turned off* throughout the backward iteration and is only needed for the last out-of-sample expectation.

Specifying a particular emulator is therefore straightforward, as the required API only asks for **fit** and **predict** methods. For instance, all the R packages in the Regression view satisfy these requirements and hence can be straightforwardly used (unfortunately, the packages do different in the exact syntax of their **predict** method, e.g. have different ways of inputting new data, or return structures with different fields for the actual predicted mean response, so manual adjustments are sometimes needed and hence are implemented under the hood of **mlOSP**.

In contrast, there are multiple aspects of simulation design that could be envisioned and implemented:

* Random or deterministic

* Replicated or Unique

* Adaptive or pre-specified

* Joint or product across the coordinates of $\bm{X}$

In a nutshell, the design geometry is specified through a *target density* $p(t,\cdot)$, with $x^n$'s viewed as samples from that target density
\begin{align}
x^n \sim p(t, \cdot)
\end{align}
In a random design, this is precisely how samples are generated. Otherwise, there could be a discrete approximation, via a quasi Monte Carlo (QMC) sequence. The target densities could be specified only in terms of marginals, giving rise to product designs, or directly on the selected input space  ${\cal X}$. We remark that if $p(t,\cdot)$ is only supported on some subset $\tilde{\cal X}$ then it is up to the user to also specify the latter. This issue arises in the classical gridded (or more generally space-filling) designs that take $p \equiv Unif[ \tilde{\cal X}]$ and approximate the uniform target density with a discrete-Uniform approximation. 

Conventionally, a design of size $N$ would consist of $N$ unique sites $x^{1:N}$. In contrast, in a replicated design, all (some) sites appear multiple time. In a most common *batched* design, we have $N_{unique}$ distinct sites, the so-called macro-design, and each unique $x$ is then repeated $N_{rep}$ times, so that 
\begin{align}
 {\cal D} = \{ \underbrace{x^{1}, x^{1}, \ldots, x^{1}}_{N_{rep} \text{ times}}, \underbrace{x^{2}, \ldots}_{N_{rep} \text{ times}}, x^{3}, \ldots, \ldots, x^{N_{unique}} \}.
\end{align}

A replicated design allows to pre-average the corresponding $y$-values such as $\bar{y}^1 := \frac{1}{N_{rep}} \sum_{i=1}^{N_{rep}} y^{1,i}$ before applying the **fit** command, which can substantially reduce the regression overhead. This is especially relevant for non-parameteric regressions, where such pre-averaging reduces the effective data-set from $N$ to $N_{unique}$.

In the examples below we explain the various design options offered in **mlOSP**, which is perhaps the best way for the user to fully understand this aspect.


## Bringing it Back into Focus: Bermudan Option Pricing

To offer the most intuitive context for using **mlOSP**, the vignette below focuses on OSP instances coming from Bermudan option pricing. In this context, we take the point of view of a buyer of an American option, which is a financial contract that gives the holder the ability (but not the obligation) to obtain a certain payoff, contingent on the underlying asset price. For example, an American Put allows its owner the right to exchange the asset for a pre-specified strike $K$, equivalent to the payoff $(K-x)_+$. The contract has an expiration date $T$, and the exercise frequency is taken to be $\Delta t$ (such as daily). 
The state $X_t$ is then interpreted as the \emph{share price} of the asset at date $t$, which is naturally must be non-negative.
Taking into account the time-value of money, it follows that the reward function at time $t$ is
$$
  h_{Put}(t,x) = e^{-r t} (K-x)_+,
$$
where $r$ is the constant interest rate. 

With this setup, the stopping set is known as the exercise region. Another term is the timing value, $T(t,x) = q(t,x) - h(t,x)$, so that exercising is optimal when the timing value is negative. The fact that  the reward has a lower bound of zero, reflects the optionality and the fact that the holder can never lose money. It implies that $\epsilon(x)$ has a mixed distribution with a point mass of zero...

For Bermudan option pricing, the seminal breakthrough were the works of Longstaff and Schwartz [@LS] and Tsitsiklis and van Roy[@TsitsiklisVanRoy], that popularized the RMC approach in this context. Especially the former, which contained a simple toy example with $N=8$ paths has been adopted as pedagogical device to explain RMC. The LS approach proposed to use a single set of global simulations, and to adopt the full pathwise simulator. Its other insight was that due to the special structure, learning $\hat{q}$ is only necessary in-the-money, i.e. in the region where $h(t,x) >0$; otherwise it is clear that $T(t,x) > 0$ and hence $A_t(x) = 1$. 

Numerous methods have since embellished and improved LS. One particularly large strand of literature has addressed different regression variants:

* Piecewise regression with adaptive sub-grids by [@BouchardWarin10]

* Regularized regression, such as LASSO, by Kohler [@Kohler12lasso]

* Kernel regression by [@Belomestny11]

* Gaussian Process regression by Ludkovski

* Neural nets by [@Kohler10nn]

* dynamic trees by [@GL13]



# Getting Started with mlOSP

The following user guide highlights the key aspects of mlOSP. It is intended to be fully reproducible, so that the reader can simply cut-and-paste (or download the RMarkdown document online) the R code. Since all the algorithms are intrinsically based on generating random outputs based on the underlying stochastic simulator, where possible we fix the RNG seeds. Depending on the particular machine and R version, the seeds might nevertheless lead to different results.


This is achieved by utilizing, where possible, function pointers. For example, R already offers a standardized interface for regression, consisting of the *fit* and *predict* methods. **mlOSP** can then piggy-back on that interface, allowing the user to easily "hook-up" a new regression method for the regression module. Similarly, **mlOSP** can easily handle user-defined system dynamics, incorporated through constructing a new instance of path-simulator. 


Load the necessary libraries (there are quite a few since we try many different regression methods)!
```{r results="hide",warning=FALSE,message=FALSE,error=FALSE}
library(ks)
library(fields) # for plotting purposes, use quilt.plot in 2D
library(seqOSP)
library(DiceKriging)
library(tgp)  # use lhs from there
library(randtoolbox)  # use sobol and halton QMC sequences
library(randomForest)
library(earth)
library(hetGP)
library(kernlab)
```

The workflow pipeline in mlOSP consists of:

(i) Defining the `model`, which is a list of parameters that determine the dynamics of $(X_t)$, the payoff function $h(t,x)$ and the tuning parameters determining the regression specification; `model` also contains function pointers that are used to simulate $(X_t)$, compute $h(t,x)$ and ....

(ii) Calling the appropriate top-level solver. The solvers are indexed by the underlying type of simulation *design* which most affects the implementation. They also use a top-level `method` argument that selects from a collection of implemented regression modules. Otherwise, all other parameters are passed through the above `model` argument. The solver returns a collection of fitted emulators (an `R` list containing the respective regression object for each time step), plus a few diagnostics;

(iii) Evaluating the obtained fitted emulators through an out-of-sample forward simulator via the `forward.sim.policy` command. The latter is a top-level function that can work with any of the implemented regression objects. Alternatively, one may also *visualize* the emulators through a few provided plotting commands.

The following example illustrates this workflow (it will be revisited as Model A below). We use a simple 1-D Bermudan Put where the underlying dynamics are given by Geometric Brownian Motion
$$ dX_t = rX_t dt + \sigma X_t dW_t, \qquad X_0 = x_0.$$
In the model specification below we have $r=0.06, T=1, \sigma=0.2$ and the option payoff is a Put $(K-X_t)_+$ with $K=40$. The exercise is possible 25 times before expiration, i.e $\Delta t = 0.04$. 

We hand-build a few designs that cover the in-the-money region $[25,40]$ using QMC sequences. As a start we use a Gaussian Process emulator with a replicated design. The replications are treated using the SK method [@ankenman2010stochastic], pre-averaging the replicated outputs before training the GP. The GP has a constant prior mean, learned via the Universal Kriging equations (Ginsbourger et al 2013)


```{r first-example}
# a few prespecified designs
#grid1 <- c(30, 33:39)
#grid2 <- c(28, 30, seq(32.5, 39, by=0.5))
grid3 <- sort(15*sobol(15)+25)
#grid4 <- sort(15*sobol(200)+25)

# specify the simulation model, the payoff, and the emulator setup
model1 <- c(final.runs=0, K=40, option.func=put.payoff,
            x0=40,sigma=0.2,r=0.06,div=0,T=1,dt=0.04,dim=1, sim.func=sim.gbm,
            lhs.rect=c(25,40),init.size=15,km.cov=4,km.var=1, cand.len=1000,
            look.ahead=1,pilot.nsims=0,km.batch=200,covfamily="matern5_2")

put1d.model <- model1
put1d.model$N <- 500
option.payoff <- put.payoff

# use the DiceKriging Gaussian Process emulator with fixed hyperparameters specified in
# km.cov, km.var. The default kernel is Matern-5/2
km.fit <- osp.fixed.design(put1d.model,input.domain=grid3, method="km")
```

Now we visualize the results from one time-step. To do so, we first predict the timing value based on a fitted emulator (at $t=10\Delta t$ step) over a collection of points. We then plot the point estimate of $T(t,x)$ and the corresponding credible interval (which is organically provided by the GP emulator).
```{r Fitted-GP, fig.cap="Timing Value of a Bermudan Put based on GP emulator. We also display the underlying simulation design (the rug plot) and the uncertainty quantification regarding the fit of T(t,x) (the shaded 95 CI)"}
check.x <- seq(24, 40, len=500)   # predictive sites
myCol <- "grey"
km.pred <- predict(km.fit$fit[[10]],data.frame(x=check.x), type="UK") 
plot(check.x, km.pred$mean, lwd=2, type="l", xlim=c(27,40), ylim=c(-0.4,1.1), 
     xlab='X', ylab='Timing Value')
lines(check.x, km.pred$lower95, lty=2,col=myCol)  # 95% CI band, see doc of predict.km
lines(check.x, km.pred$upper95, lty=2,col=myCol)
abline(h=0,lty=2)
rug(grid3, quiet=TRUE)
```


### Key functions

The mlOSP package has several principal schemes for constructing the emulators that describe the estimated stopping rule. The emulators are 
We have:

* osp.prob.design -- this is the original Longstaff Schwartz scheme that generates forward trajectories that are then re-used as the design sites. In our notation, this is a pure probabilistic design, without any replication. It is married to a variety of regression methods, both parametric and nonparametric. 

* osp.fixed.design -- the generic RMC scheme with a pre-specified/fixed (in the sense of not sequential) design. In particular the design can be replicated using *km.batch* parameter. This approach nests the osp.prob.design when km.batch=1 and the input.domain is fully specified. 

* osp.probDesign.piecewisebw -- this is the Bouchard Warin implementation of RMC that utilizes a hierarchical (piecewise) linear model based on an equi-probable partition of the forward trajectory sites. Since we have a ``quick-and-dirty'' recursive construction of the sub-domains, the fits from this function *cannot* be fed into a forward simulator. However, the function directly accepts a collection of test trajectories that are evaluated in parallel with the backward DP iteration. 

* mc.put.adaptree -- sequential RMC with *dynaTree* emulators

* osp.seq.design --- sequential RMC with GP (ie Stochastic Kriging) emulators that are used to construct sequential design acquisition functions via the posterior emulator variance


## Different types of regression emulators

### 2D Average Put example
Next we try a 2D example where things get a bit more interesting. Here the payoff is the basket average Put,
$$ (K - (X_1+X_2)/2)_+$$. We continue to use $K=40$. Thus, the option is in-the-money when $X_1+X_2 > 80$ in the example below. For the initial condition we primarily use $(40,40)$ which is At-the-money.

The two assets are assumed to be uncorrelated and with identical dynamics, thus the whole metamodel should be symmetric in $X_1,X_2$.

```{r 2D-test}
al.params.km <- list(adaptive.grid.loop=100,look.ahead=1,init.size=100,final.runs=0,
                     al.heuristic='sur',cand.len=1000,
                     km.batch=100,km.var=4,km.cov=c(6,6),km.upper=c(10,10))
lsmc.params <- list(mars.pen=1.5, mars.len=6,mars.thresh=1e-8,nChildren=5,
                    rf.ntree=200,rf.nodesize=40,rf.maxnode=100)

model2d <- c(al.params.km, list(K=40,x0=rep(40,2),sigma=rep(0.2,2),r=0.06,div=0,
                                T=1,dt=0.04,dim=2,sim.func=sim.gbm))
option.payoff <- put.payoff
```

Test with a regular OLS regression against polynomial bases: a total of N=15000 training paths. To do so, we first manually define the basis functions that are passed to the **bases** model parameter, utilized when the method is set to "lm". Below we use a total of 5 bases $x_1, x_1^2, x_2, x_2^2, x_1 x_2$ (be default **lm** also includes the constant term, so there are a total of 6 regression coefficients $\vec{\beta}$).

```{r lm-polynomials}
bas22 <- function(x) return(cbind(x[,1],x[,1]^2,x[,2],x[,2]^2,x[,1]*x[,2]))
model2d$bases <- bas22

# subset= controls how the total of 30K simulations are split between training and testing
# Here we use a 50/50 split
prob.lm <- osp.prob.design(30000,model2d,method="lm",subset=1:15000)
```

Repeat with GP: design of 150 sites replicated with 100 each. Uses the Gaussian squared-exponential kernel.
```{r Same-with-GP, fig.cap="Timing Value of a 2D Basket Put. The contour shows the boundary of the stopping set (bottom-left corner)."}
lhs.rect <- matrix(0, nrow=2, ncol=2)
lhs.rect[1,] <- c(25,55)  # atm is x1+x2 < 80
lhs.rect[2,] <- c(25,55)
model2d$lhs.rect <- lhs.rect
model2d$pilot.nsims <- 0
model2d$N <- 150
model2d$covfamily <- "gauss"

sob150 <- sobol(276, d=2)
sob150 <- sob150[ which( sob150[,1] + sob150[,2] <= 1) ,]  # a lot are on the diagonal
sob150 <- 25+30*sob150

sob.km <- osp.fixed.design(model2d,input.domain=sob150, method="km")
require(fields)
plt.2d.surf( sob.km$fit[[15]], x=seq(25,50, len=101), y=seq(25,50,len=101), ub=10)
```
The above plot visualizes the stopping boundary (red contour) and the fitted timing value (the stopping region is the level set where the timing value is negative). We also display the underlying Sobol QMC design of size 150.

To do a proper comparison between the fits we create a single out-of-sample database and run both stopping rules on it.
```{r fig.cap="Comparing out-of-sample payoffs using LM and GP emulators"}
NN <- 16000
MM <- 25
set.seed(101)
mygr <- list()
mygr[[1]] <- model2d$sim.func( matrix(rep(model2d$x0, NN), nrow=NN, byrow=T), 
                               model2d, model2d$dt)
for (i in 2:(MM+1))
   mygr[[i]] <- model2d$sim.func( mygr[[i-1]], model2d, model2d$dt)
# sanity check: European option value
print(mean( exp(-model2d$r*model2d$T)*option.payoff(K=40,mygr[[MM]])))
oos.lm <- forward.sim.policy( mygr, MM, prob.lm$fit, model2d)
oos.km <- forward.sim.policy( mygr, MM, sob.km$fit,  model2d)
print( c(mean(oos.lm$payoff), mean(oos.km$payoff)) )
plot(oos.lm$payoff, oos.km$payoff)
```


The first function is **osp.prob.design**. This is  classical RMC that builds a design using a forward simulation of state trajectories.
Its main input is the *method* which can take a large range of regression methods. Specifics of each regression are controlled through specifying *required* respective model parameters. The code snippet below reuses the 1D model to instead apply a **smooth.spline** (smoothing cubic spline) regressor. The latter requires specifying the number of knots. Only 2 lines of code are necessary to make this modification to the above OSP instance.

```{r 1d-spline}
put1d.model$nk=20  # number of knots for the smoothing spline
spl.eml.1dput <- osp.prob.design(30000,put1d.model,subset=1:10000,method="spline")
```

The second function **osp.probDesign.piecewisebw** runs the[@BouchardWarin10] algorithm . This is a variant of the Longstaff-Schwartz scheme [@LS] utilizing piecewise linear regressions. The regresion sub-domains are picked adaptively based on equi-probable partition of the generated trajectories. The partition uses *model.nChildren* bins in each dimension. 

The third function is  **osp.fixed.design**. It has three key parameters: `input.domain` which controls the construction of the design, `km.batch` that controls the replication amount and type which controls the regression method. Because the design is now user-specified, its size can vary step-by-step. The package also allows to vary the replication amounts. Several options are available to build a space-filling design, in particular in terms of 
generating the bounding hyper-rectangle that defines the effective input space:

(i) Directly utilizing  a user-defined simulation design. For example, we can use a Sobole QMC sequence to place $x^{1:N}_{t}$. 

(ii) Secondly, one can construct the bounding rectangle through some pilot simulations of $X_{0:T}$. Here *input.dom=0.02* makes the LHS space-fill a box between the 2nd and 98th percentiles of the `pilot.nsim=1000` pilot trajectories at each time step. The pilot trajectories act as "scaffolding," organically expanding the input domain as $t$ grows.
If we set *input.dom=-1* then the full range of the pilot scenarios is used. Here we space-fill using a Halton QMC sequence.

(iii) ....

We may also make the design size $N_t$ to change over $t$ which is entered by making the *model.N* parameter a vector.

### Regression Methods:

* `lm`: linear model, specified through the set of user-provided basis functions, defined via `bases` parameter;

* `rf`: random forest model, specified through the number of trees `rf.ntree` and `rf.maxnode`

* `mars`: multivariate adaptive regression spline model from the `earth` package, specified through `put1d.model$earth.deg = 2`; `put1d.model$earth.nk = 100`; `put1d.model$earth.thresh = 1e-8` We set the degree to be 2, so that bases consist of linear/quadratic hinge functions.

* `spline`: smoothing splines (only in 1D)

* `km`: Gaussian process model from the DiceKriging package with fixed GP hyperparameters

* `trainkm`: trained GP model

* `hetgp`: The classical GP emulator assumes homoskedastic Gaussian simulation noise. To tackle the strong heteroskedasticity encountered in our context, we have utilized above the Stochastic Kriging (SK) approach [@ankenman2010stochastic]. SK utilizes a replicated design to locally estimate $\sigma^2(x) = \mathbb{Var}(\epsilon(x))$. This estimation is done empirically via the classical MC variance estimator based on the batch of $r$ pathwise rewards starting at the same $x$:
$$ \hat{\sigma^2(x)} = \frac{1}{r-1} \sum_{i=1}^r (y^i - \bar{y})^2.$$
To be reliable, this strategy necessitates using large batch sizes $r$ (called **n.reps** in mlOSP); in practice we find that $r \gg 20$ is necessary. For example, in the previous example we used $n.reps = 100$.  An alternative framework directly aims to learn $\sigma^2(\cdot)$ via a second spatial model that is jointly inferred with the standard mean response. This has been recently implemented [@binois2016practical] in the **hetGP** package that we now illustrate. The main advantage of using **hetGP** is the ability to lower the replication counts.

* `homtp`

* RVM kernel regression from **kernlab**. 

* `np`:   A different kernel package is *np*. Below we use it with a Epanechnikov order-4 kernel and local-linear regression. The bandwidth is estimated using least squares cross-validation (default **npreg** option)## Sequential Designs

### Sequential design
The function **osp.seq.design** generates sequential designs. It start with an initial design of size init.size and grows it until adaptive.grid.loop size. Below we start with 30 well-placed design sites, and add an additional 120, for a total of 150, with 20 replications each. The designs are augmented based on an *acquisition function*, specified via the **al.heuristic** parameter. Currently, 5 different acquisition functions are implemented, see [Binois et al 2018]: 

  * acquisition function ("smcu", "tmse", "sur", "csur", "amcu")
  
  
Note that the regression emulator, must be currently of GP-type to provide the needed posterior variance ("km","hetgp", "homtp")

```{r sequential-km, fig.width=5, fig.height=3,fig.cap="Sequential Design using SUR acquisition function"}
require(laGP)  # needed for distance function 
sob30 <- randtoolbox::sobol(55, d=2)
sob30 <- sob30[ which( sob30[,1] + sob30[,2] <= 1) ,]  # a lot are on the diagonal
sob30 <- 25+30*sob30
 
option.payoff <- put.payoff
model2d$adaptive.grid.loop <- 150  # final design size -- a total of 3000
model2d$km.batch <- 20
model2d$init.size <- 30   # initial design size
model2d$init.grid <- sob30
model2d$al.heuristic <- "sur"
model2d$covfamily <- "matern5_2"
put2d.sur.km <- osp.seq.design(model2d)
oos.sur.km <- forward.sim.policy( mygr, MM, put2d.sur.km$fit, model2d)
print(mean(oos.sur.km$payoff))
plt.2d.surf(put2d.sur.km$fit[[18]],x=seq(26,48,len=101),y=seq(26,48,len=101),
            sub=sprintf("%4f",mean(oos.sur.km$payoff)))
```


#########################
# Old stuff
First we consider a 1D example  with **smooth.spline**.  Note the syntax: we use a total of 30000 trajectories, of which the first 10000 are reserved for testing, and the last 20000 is the training set. We then also run a **randomForest**.

**osp.probDesign.piecewisebw** function runs the Bouchard-Warin algorithm [@BouchardWarin10]. This is a variant of the Longstaff-Schwartz scheme [@LS] utilizing piecewise linear regressions. The regresion sub-domains are picked adaptively based on equi-probable partition of the generated trajectories. The partition uses *model.nChildren* bins in each dimension, so for the 2d problem below, taking nChildren=10 and $N=40000$ implies having 100 sub-domains with 400 trajectories in each. As can be seen, the role of nChildren is very crucial for algorithm performance.


```{r 1d-spline-RF}
put1d.model$nk=20  # number of knots for the smoothing spline
spl.eml.1dput <- osp.prob.design(30000,put1d.model,subset=1:10000,method="spline")
put1d.model$rf.ntree = 200  # random forest parameters
put1d.model$rf.maxnode=100
rf.eml.1dput <- osp.prob.design(30000,put1d.model,subset=1:10000,method="randomforest")
```

As a a last example, We try **MARS** (multivariate adaptive regression splines) from the **earth** package. We set the degree to be 2, so that bases consist of linear/quadratic hinge functions.
```{r 1d-MARS}
put1d.model$earth.deg = 2;  # earth parameters
put1d.model$earth.nk = 100;
put1d.model$earth.thresh = 1e-8
mars.eml.1dput <- osp.prob.design(30000,put1d.model,subset=1:10000,method="earth")
```

## Space-filling Batched designs

The second function, which is the workhorse of mlOSP, is **osp.fixed.design**. It has three key parameters: `input.domain` which controls the construction of the design, `km.batch` that controls the replication amount and type which controls the regression method. Because the design is now user-specified, its size can vary step-by-step. The package also allows to vary the replication amounts.

We proceed to an overview of different ways to build a space-filling design. The main issue is how to
generate the bounding hyper-rectangle that defines the effective input space. The package provides several ways to do so.

The first example utilizes a user-defined simulation design that is used as-is. The  constructed ``sob150'' macro-design places 150 design sites in a trianglular input domain, using a Sobol QMC sequence. For the latter we employ the *sobol* function in the  **randtoolbox** package. Based on model parameters, the input domain is the lower-left triangle of $[25,55]^2$. Every site is then batched with 100 replications/site for a total simulation budget of $N=15000$.

The **plt.2d.surf** function provides a way to visualize the emulator of $q(t,\cdot)$ at a single time-step, showing both the timing value $T(t,\cdot)$ and the stopping boundary (which is the zero-contour of the latter). It also shows the respective design ${\cal D}_t$ (the 150 points).

```{r Sobol-pre-specified,fig.cap="Space-fillnig Sobol Design and a DiceKriging GP Emulator with fixed hyper-parameters for the 2d Bermudan Put at $t=0.4$"}
sob150 <- sobol(276, d=2)
sob150 <- sob150[ which( sob150[,1] + sob150[,2] <= 1) ,]  # a lot are on the diagonal
sob150 <- 25+30*sob150

model2d$km.batch <- 100
model2d$pilot.nsims = 0
model2d$covfamily="matern5_2"
model2d$N = 500   # size of unique design sites; only in-the-money sites are kept

put2d.sobol.km <- osp.fixed.design(model2d,input.dom=sob150, method="km")
plt.2d.surf(put2d.sobol.km$fit[[10]], x=seq(24,52,len=101),y=seq(24,52,len=101),ub=10)
```

Secondly, we use an adaptive LHS design using some pilot simulations of $X_{0:T}$. Here *input.dom=0.02* makes the LHS space-fill a box between the 2nd and 98th percentiles of the pilot.nsim=1000 pilot trajectories at each time step. The pilot trajectories act as "scaffolding," organically expanding the input domain as $t$ grows.
```{r LHS-quantile-design,fig.cap="LHS Space-filling design. Left: t=0.4, Right: t=0.8"}
model2d$pilot.nsims <- 1000
model2d$N = 500   # size of unique design sites; only in-the-money sites are kept
model2d$qmc.method <- NULL
put2d.lhsAdaptive.km <- osp.fixed.design(model2d,input.dom=0.02, method="km")
par(mfrow=c(1,2))
plt.2d.surf(put2d.lhsAdaptive.km$fit[[10]],x=seq(24,52,len=101),y=seq(24,52,len=101))
plt.2d.surf(put2d.lhsAdaptive.km$fit[[20]],x=seq(24,52,len=101),y=seq(24,52,len=101))
```

If we set *input.dom=-1* then the full range of the pilot scenarios is used. Here we space-fill using a Halton QMC sequence.
In addition, we also train the **DiceKriging** GP hyperparameters, which is the Stochastic Kriging metamodel. Here for variety sake we pick a Gaussian covariance kernel.
```{r Halton-probabilistic-design,fig.cap="Halton QMC Space-filling Design with a trained DiceKriging emulator. Left: t=0.4; Right: t=0.8."}
model2d$pilot.nsims <- 1000
model2d$km.upper <- 20
model2d$N = 500   # size of unique design sites; only in-the-money sites are kept
model2d$qmc.method <- randtoolbox::halton
model2d$covfamily <- "gauss"
put2d.haltonRange.trainkm <- osp.fixed.design(model2d,input.dom=-1, method="trainkm")
par(mfrow=c(1,2))
plt.2d.surf(put2d.haltonRange.trainkm$fit[[10]],x=seq(26,48,len=101),y=seq(26,48,len=101))
plt.2d.surf(put2d.haltonRange.trainkm$fit[[20]],x=seq(26,48,len=101),y=seq(26,48,len=101))
coef(put2d.haltonRange.trainkm$fit[[15]])
```


### Heteroskedastic GP emulator

The classical GP emulator assumes homoskedastic Gaussian simulation noise. To tackle the strong heteroskedasticity encountered in our context, we have utilized above the Stochastic Kriging (SK) approach [@ankenman2010stochastic]. SK utilizes a replicated design to locally estimate $\sigma^2(x) = \mathbb{Var}(\epsilon(x))$. This estimation is done empirically via the classical MC variance estimator based on the batch of $r$ pathwise rewards starting at the same $x$:
$$ \hat{\sigma^2(x)} = \frac{1}{r-1} \sum_{i=1}^r (y^i - \bar{y})^2.$$
To be reliable, this strategy necessitates using large batch sizes $r$ (called **n.reps** in mlOSP); in practice we find that $r \gg 20$ is necessary. For example, in the previous example we used $n.reps = 100$. 

An alternative framework directly aims to learn $\sigma^2(\cdot)$ via a second spatial model that is jointly inferred with the standard mean response. This has been recently implemented [@binois2016practical] in the **hetGP** package that we now illustrate. The main advantage of using **hetGP** is the ability to lower the replication counts
```{r hetGP-2D, fig.align="center", fig.cap="hetGP emulator"}
model2d$pilot.nsims <- 1000
model2d$km.upper <- 20
model2d$km.batch <- 25
model2d$covfamily <- "Matern5_2"  
# note that hetGP has a slightly different naming convention for kernels
model2d$N <- c(rep(400,10), rep(600,10), rep(800,5))   # size of unique design sites;  only in-the-money sites are kept
model2d$qmc.method <- randtoolbox::halton
put2d.haltonAdaptive.hetgp <- osp.fixed.design(model2d,input.dom=0.02, method="hetgp")
par(mfrow=c(1,3))
plt.2d.surf(put2d.haltonAdaptive.hetgp$fit[[6]],x=seq(26,48,len=101),y=seq(26,48,len=101))
plt.2d.surf(put2d.haltonAdaptive.hetgp$fit[[14]],x=seq(26,48,len=101),y=seq(26,48,len=101))
plt.2d.surf(put2d.haltonAdaptive.hetgp$fit[[22]],x=seq(26,48,len=101),y=seq(26,48,len=101))
summary(put2d.haltonAdaptive.hetgp$fit[[14]])
```

We can also use a probabilistic design based on the pilot trajectories. Note that this still embeds the replication aspect. To showcase the flexibility, here we make the design size change over $t$, using larger design for latter steps where the input domain is bigger. The pattern for design size $N_t$ is entered by making the *model.N* parameter a vector.

```{r time-varying-design-size, fig.asp=0.6, fig.align="center", out_width="80%",fig.cap="DiceKriging emulator with time-varying design sizes. Left: t=0.24; Middle: t=0.56, Right: t=0.88. As t increases the input domain grows organically."}
option.payoff <- put.payoff
model2d$pilot.nsims <- 1000
model2d$km.batch <- 100
model2d$covfamily <- "matern5_2"
model2d$N <- c(rep(400,10), rep(600,10), rep(800,5))  
# time-varying design size (sub-sampled from the pilot trajectories)

put2d.probRep.km <- osp.fixed.design(model2d,input.dom=NULL, method="km")
par(mfrow=c(1,3))
plt.2d.surf(put2d.probRep.km$fit[[6]],x=seq(26,48,len=101),y=seq(26,48,len=101))
plt.2d.surf(put2d.probRep.km$fit[[14]],x=seq(26,48,len=101),y=seq(26,48,len=101))
plt.2d.surf(put2d.probRep.km$fit[[22]],x=seq(26,48,len=101),y=seq(26,48,len=101))
```

After having built all these models we can do horse racing on a fixed out-of-sample set of scenarios. We use $N'=40000$ trajectories with a different initial condition $X_0 = (41,40)$ and compute the payoffs from 4 different GP schemes.

```{r out-of-sample-comparison}
NN <- 40000
MM <- 25
set.seed(102)
test.2d <- list()
# use a different starting point for X_0
test.2d[[1]] <- model2d$sim.func( matrix(rep(c(41,40), NN), nrow=NN, byrow=T), 
                                  model2d, model2d$dt)
for (i in 2:(MM+1))
   test.2d[[i]] <- model2d$sim.func( test.2d[[i-1]], model2d, model2d$dt)
# sanity check: European option value
print(mean( exp(-model2d$r*model2d$T)*option.payoff(K=40,test.2d[[MM]])))
oos.1 <- forward.sim.policy( test.2d, MM, put2d.probRep.km$fit, model2d)
oos.2 <- forward.sim.policy( test.2d, MM, put2d.haltonRange.trainkm$fit,  model2d)
oos.3 <- forward.sim.policy( test.2d, MM, put2d.haltonAdaptive.hetgp$fit,  model2d)
oos.4 <- forward.sim.policy( test.2d, MM, put2d.lhsAdaptive.km$fit,  model2d)
print( c(mean(oos.1$payoff), mean(oos.2$payoff), mean(oos.3$payoff), mean(oos.4$payoff)) )
```

## 3D Max Call Example

The following example is from Broadie and Glasserman 1997 paper. The true answer is about $V(0,X_0)=11.25$ under continuous exercise optionality. Here we follow the Andersen Broadie article [@Broadie] in taking a crude $\Delta t = 1/3$ dicretization with just $K=9$ exercise dates. The test set has $N'=40000$ paths.
```{r 3d-lm}
# 3D MaxCall
call3d.params <- list(adaptive.grid.loop=250,look.ahead=1,init.size=200,final.runs=0,
                      al.heuristic='sur',cand.len=1000,
                      km.batch=80,km.var=20,km.cov=c(12.5,12.5,12.5),km.upper=c(20,20,20))

# Also in Andersen Broadie (MS'04), Table 2 p. 1230
modelBrGl3d <- c(call3d.params, list(K=100, r=0.05, div=0.1, sigma=rep(0.2,3),T=3, dt=1/3,
  x0=rep(90,3),dim=3, sim.func=sim.gbm,N=1000,pilot.nsims=100, covfamily="Matern5_2"))
option.payoff <- maxCall

# Generate out-of-sample test set
set.seed(44)
NN <- 10000
MM <- 9
test.3d <- list()
test.3d[[1]] <- sim.gbm( matrix(rep(modelBrGl3d$x0, NN), nrow=NN, byrow=T), modelBrGl3d)
for (i in 2:MM)
   test.3d[[i]] <- sim.gbm( test.3d[[i-1]], modelBrGl3d)
# European option price
mean( exp(-modelBrGl3d$r*modelBrGl3d$T)*option.payoff(K=100,test.3d[[MM]]))  
```

### Kernel Regressions
Another emulator that we haven't used yet is the RVM kernel regression from **kernlab**. Below the total design size is $N = 20000 = 800 \cdot 25$, with $r=25$ replicates per site. 

```{r call3d-rvm}
modelBrGl3d$N <- 800
modelBrGl3d$km.batch <- 25
lhs.rect <- matrix(0, nrow=3, ncol=2)
lhs.rect[1,] <- lhs.rect[2,] <- lhs.rect[3,] <- c(50,150)

call3d.lhsFixed.rvm <- osp.fixed.design(modelBrGl3d,input.domain=lhs.rect, method="rvm")
oos.rvm <- forward.sim.policy(test.3d,MM,call3d.lhsFixed.rvm$fit,modelBrGl3d,compact=TRUE)
print(c(mean(oos.rvm$payoff), call3d.lhsFixed.rvm$nsims, 
        as.numeric(call3d.lhsFixed.rvm$timeElapsed)))
```
REMARK that number of simulations is random


A different kernel package is *np*. Below we use it with a Epanechnikov order-4 kernel and local-linear regression. The bandwidth is estimated using least squares cross-validation (default **npreg** option)
```{r call3d-npreg,results="hide"}
require(np)
modelBrGl3d$N <- 800
modelBrGl3d$km.batch <- 25
modelBrGl3d$qmc.method <- randtoolbox::sobol
modelBrGl3d$np.kertype <- "gaussian"
modelBrGl3d$np.kerorder <- 2
modelBrGl3d$np.regtype <- "lc"
lhs.rect <- matrix(0, nrow=3, ncol=2)
lhs.rect[1,] <- lhs.rect[2,] <- lhs.rect[3,] <- c(50,150)

call3d.sobFixed.np <- osp.fixed.design(modelBrGl3d,input.domain=lhs.rect, method="npreg")
oos.np <- forward.sim.policy( test.3d,MM,call3d.sobFixed.np$fit,modelBrGl3d,compact=TRUE)
print(c(mean(oos.np$payoff), call3d.sobFixed.np$nsims, as.numeric(call3d.sobFixed.np$timeElapsed)))
```


Running this again with the **DiceKriging** (km) emulator based on Stochastic Kriging. 

```{r call3d-km}
modelBrGl3d$N <- 800
modelBrGl3d$km.batch <- 25
modelBrGl3d$covfamily <- "matern5_2"
set.seed(1)
km.stats.bg3 <- array(0, dim=c(5,4))
# do it 5 times to see the rough spread across macro-replications
for (j in 1:5) {
  #modelBrGl3d$init.size <- 80+4*(j-1)
  call3d.lhsFixed.km <- osp.fixed.design(modelBrGl3d,input.domain=lhs.rect, method="km")  
  oos <- forward.sim.policy( test.3d,MM,call3d.lhsFixed.km$fit,modelBrGl3d,compact=TRUE)
  km.stats.bg3[j,1:3] <- c(mean(oos$payoff), call3d.lhsFixed.km$nsims, as.numeric(call3d.lhsFixed.km$timeElapsed))
  #oos <- forward.sim.policy( mygr.itm,MM,lhs.run$fit,modelBrGl3d,offset=1,compact=TRUE)
  #km.stats.bg3[j,4] <- mean(oos$payoff)
}
```

We then compare to a piecewise-linear LM. It runs in under 15 seconds even for $N=300000= 3 \cdot 10^5$ paths. 
```{r piecewise-lm}
bw.run <- osp.probDesign.piecewisebw(300000,modelBrGl3d,test=test.3d)  #get 10.9
```

We now run a global linear regression using polynomial bases. Here we utilize all possible monomials and their products with total degree up to 3, for a total of 20 bases. To avoid over-fitting, we work with $N=320000$ (320 thousand) paths. This large-scale example is to illustrate the poor scalability of the conventional RMC which might easily demand significant memory resources.
```{r lm-method,fig.cap="Distribution of V(0,x_0) in-sample (left) and out-of-sample(right)"}
# run probabilistic design with polynomial bases
bas2 <- function(x) return(cbind(x[,1],x[,1]^2,x[,2],x[,2]^2,x[,1]*x[,2],x[,3],x[,3]^2,
                                 x[,3]*x[,2],x[,1]*x[,3]))

bas3 <- function(x) return(cbind(x[,1],x[,1]^2,x[,2],x[,2]^2,x[,1]*x[,2],x[,3],x[,3]^2,
                                 x[,3]*x[,2],x[,1]*x[,3], x[,1]^3,x[,2]^3,x[,3]^3,
                             x[,1]^2*x[,2],x[,1]^2*x[,3],x[,2]^2*x[,1],x[,2]^2*x[,3],
                             x[,3]^2*x[,1],x[,3]^2*x[,2],x[,1]*x[,2]*x[,3] ))
modelBrGl3d$bases <- bas3

# do 25 macro-replications
stats.3dcall <- array(0, dim=c(25,3))
for (j in 1:25) {   
  lm.run <- osp.prob.design(320000,modelBrGl3d,method="lm",subset=1:20000)
  oos.lm <- forward.sim.policy(test.3d, MM, lm.run$fit, modelBrGl3d) 
  stats.3dcall[j,] <- c(lm.run$p[1], mean(oos.lm$payoff),as.numeric(lm.run$timeElapsed))
}
# display the resulting sampling distribution of Call price
boxplot(cbind(stats.3dcall[,1], stats.3dcall[,2]), names=c('In Sample', 'Out of Sample'))
points(rep(1,25), stats.3dcall[,1], col="red")  # in-sample
points(rep(2,25), stats.3dcall[,2], col="steelblue", pch=19) # out of sample is lower
```

The plot above visualizes the sampling distribution of the ultimate estimator $\hat{V}(0,X_0)$ as a function of the *training* set. The loop in $j$ repeats the whole RMC algorithm (in its classical Longstaff-Schwartz format, i.e. with probabilistic design based on global paths and a linear parametric regression emulator). We then capture the variability of $\hat{V}(0,X_0)$ based on a *fixed test set* of $N'$ out-of-sample paths. 

Heuristically, it has been observed that the in-sample estimator that is available in the global-path design approach tends to give *upper* bounds, and hence can be used to roughly ``sandwich'' the final estimate of the option price between the lower bound of the test set and the upper bound of the training set. 

More efficient algorithms would be expected to yield lower sampling variance, i.e. less dependence on the particular training set. Statistically, this dependence is primarily driven by the sensitivity of the regression emulator to the realizations in $y^{1:N}_t$; it is well known that the linear parametric model employed above is quite sensitive in that regard, e.g. to ``outliers''. A secondary effect is also coming from the simulation design $x^{1:N}_t$ which is here random and hence varies across macro-runs. The latter effect could of course be entirely avoided if a fixed simulation design is selected, such as one of the pre-specified space-filling QMC designs.

### Piecewise regression based on Bouchard-Warin

The **osp.probDesign.piecewisebw** function runs the Bouchard-Warin algorithm [@BouchardWarin10]. This is a variant of the Longstaff-Schwartz scheme [@LS] utilizing piecewise linear regressions. The regresion sub-domains are picked adaptively based on equi-probable partition of the generated trajectories. The partition uses *model.nChildren* bins in each dimension, so for the 2d problem below, taking nChildren=10 and $N=40000$ implies having 100 sub-domains with 400 trajectories in each. As can be seen, the role of nChildren is very crucial for algorithm performance.

The example below uses a 2D Stochastic Volatility model with a Put payoff from the [@Rambharat11] article.

```{r bouchard-warin-2d-sv}
option.payoff <-sv.put
set.seed(1)
modelSV5 <- list(K=100,x0=c(90, log(0.35)),r=0.0225,div=0,sigma=1,
    T=50/252,dt=1/252,svAlpha=0.015,svEpsY=1,svVol=3,svRho=-0.03,svMean=2.95,
    eulerDt=1/2520, dim=2,sim.func=sim.expOU.sv,nChildren=10)
putPr <- osp.probDesign.piecewisebw(40000,modelSV5)
 # get putPr$price= 16.81677
# now try again with a different number of partitions
modelSV5$nChildren <- 8
putPr2 <- osp.probDesign.piecewisebw(40000,modelSV5)
  
```

## Sequential Designs

The function **osp.seq.design** generates sequential designs using the SUR heuristic. It start with an initial design of size init.size and grows it until adaptive.grid.loop size. Below we start with 30 well-placed design sites, and add an additional 120, for a total of 150, with 20 replications each. The designs are augmented based on an *acquisition function*, specified via the **al.heuristic** parameter. Currently, 5 different acquisition functions are implemented, see [Binois et al 2018]. To illustrate the possibility, we present 3 different versions that among them vary:

  * acquisition function ("mcu", "tmse", "sur")
  
  * regression emulator, which currenlty must be of GP-type to provide the needed posterior variance ("km","hetgp", "homtp")
  * Total design size $N$ (150, 120) and  batching $r$ (25, 80)
  
We reuse the test set from the very first example.

```{r sequential-km, fig.width=5, fig.height=3,fig.cap="Sequential Design using SUR acquisition function"}
require(laGP)  # needed for distance function 
sob30 <- randtoolbox::sobol(55, d=2)
sob30 <- sob30[ which( sob30[,1] + sob30[,2] <= 1) ,]  # a lot are on the diagonal
sob30 <- 25+30*sob30
 
option.payoff <- put.payoff
model2d$adaptive.grid.loop <- 150  # final design size -- a total of 3000
model2d$km.batch <- 20
model2d$init.size <- 30   # initial design size
model2d$init.grid <- sob30
model2d$al.heuristic <- "sur"
model2d$covfamily <- "matern5_2"
put2d.sur.km <- osp.seq.design(model2d)
oos.sur.km <- forward.sim.policy( mygr, MM, put2d.sur.km$fit, model2d)
print(mean(oos.sur.km$payoff))
plt.2d.surf(put2d.sur.km$fit[[18]],x=seq(26,48,len=101),y=seq(26,48,len=101),
            sub=sprintf("%4f",mean(oos.sur.km$payoff)))
```

Second combo is tMSE/hetGP 

```{r sequential-hetgp,fig.cap="Sequential Design using tMSE acquisition function with hetGP",results="hide"}
model2d$al.heuristic <- "tmse"
model2d$tmse.eps <- 0.06
model2d$covfamily <- "Matern5_2"
put2d.tmse.hetgp <- osp.seq.design(model2d,method="hetgp")
oos.tmse.hetgp <- forward.sim.policy( mygr, MM, put2d.tmse.hetgp$fit, model2d)
plt.2d.surf(put2d.tmse.hetgp$fit[[10]],x=seq(26,48,len=101),y=seq(26,48,len=101),
            sub=sprintf("%4f",mean(oos.tmse.hetgp$payoff)))
```

Last combo is MCU/TP (homoskedastic Spatial Student $t$-Process)
```{r sequential-homtp,fig.cap="Sequential Design using MCU acquisition function"}
model2d$al.heuristic <- "mcu"
model2d$covfamily <- "Gaussian"
put2d.mcu.tp <- osp.seq.design(model2d,method="homtp")
# for (i in 1:26)
#  mygr2[[i]] <- drop( test[,,i,1])
oos.mcu.tp <- forward.sim.policy( mygr, MM, put2d.mcu.tp$fit, model2d)
plt.2d.surf(put2d.mcu.tp$fit[[10]],x=seq(26,48,len=101),y=seq(26,48,len=101),
            sub=sprintf("%4f",mean(oos.mcu.tp$payoff)))
```

### 1D Put Example
We revisit the 1D Put example. Start with a grid of size 16 and go up to 100 total, or $N=1000$ simulations.
```{r 1dput-sequential,fig.cap="1D Sequential Design for the Bermudan Put. $t=0.6$ with $T=1$"}
require(laGP)  # needed for distance function 
model.seq1d <- put1d.model

option.payoff <- put.payoff
model.seq1d$adaptive.grid.loop <- 100  # final design size 
model.seq1d$km.batch <- 10
model.seq1d$init.size <- 16  # initial design size
model.seq1d$init.grid <- as.matrix(seq(25,40,length=16))
model.seq1d$lhs.rect <- matrix(c(25,40),ncol=2)
model.seq1d$al.heuristic <- "sur"
model.seq1d$covfamily <- "Matern5_2"
model.seq1d$km.upper <- 8
put1d.sur.hetgp <- osp.seq.design(model.seq1d, method="hetgp")
check.x <- matrix(seq(24, 40, len=500))   # predictive sites
sur.pred <- predict(put1d.sur.hetgp$fit[[15]],x=check.x)  # at t=0.6
plot(check.x, sur.pred$mean, lwd=2, type="l", xlim=c(25,40), ylim=c(-0.8,1.2), 
     xlab='X', ylab='Timing Value')
lines(check.x, sur.pred$mean+2*sqrt(sur.pred$sd2), lty=2,col="grey")  # 95% CI band
lines(check.x, sur.pred$mean-2*sqrt(sur.pred$sd2), lty=2,col="grey")
abline(h=0,lty=2)
rug(put1d.sur.hetgp$fit[[15]]$X0, quiet=TRUE)
rug(model.seq1d$init.grid, quiet=TRUE, col="red",ticksize=0.05)
```

```{r}
# out-of-sample evaluation
NN <- 40000
MM <- 25
set.seed(102)
test.1d <- list()
test.1d[[1]] <- model.seq1d$sim.func(matrix(rep(40, NN), nrow=NN, byrow=T), 
                                     model.seq1d, model.seq1d$dt)
for (i in 2:(MM+1))
   test.1d[[i]] <- model.seq1d$sim.func( test.1d[[i-1]], model.seq1d, model.seq1d$dt)
oos.hetgp.1d <- forward.sim.policy( test.1d, MM, put1d.sur.hetgp$fit, model.seq1d)
print(mean(oos.hetgp.1d$payoff))
```

## Building a New Model
As an example of how the user may easily work with **mlOSP**, we proceed to show the step-by-step process of implementing a new example based on the recent article by Cheridito et al (arxiv.org/1804.05394 [@CheriditoJentzen18]).

Specifically we consider a multivariate GBM model with asymmetric volatilities and constant correlation. The payoff functional is of the max-Call type already described above. We have
$$ \label{eq:multi-gbm}
S^i_t = s^i_0 \exp( [r-\delta_i-\sigma_i^2/2]t + \sigma_i W_t^i), \qquad i=1,\ldots, d
$$
where the instantaneous correlation between $W^i$ and $W^j$ is $\rho_{ij}$. In the asymmetric example of Becker et al, $d=5, s^i_0 = s_0, \delta_i = \delta, \rho_{ij} = \rho$ and $\sigma_i = 0.08 i$ with other parameter values $\delta = 10\%, r = 5\%, \rho  = 0$ and contract specification $s_0 = 90, T=3, K=100, M=9$. 

We first define a new simulation function using the *rmvnorm* function in the **mvtnorm** library. To avoid passing too many parameters, we introduce new *model* fields *rho* (taken to be a constant) and *sigma* (a vector of length d).

```{r}
require(mvtnorm)
sim.corGBM <- function( x0, model, dt)
{
    sigm <- kronecker(model$sigma, t(model$sigma))  # matrix of sigma_i*sigma_j
    # correct the diagonal to be sigma_i^2
    sigm <- model$rho*sigm + (1-model$rho)*diag(model$sigma^2)  
    
    # implement the correlated GBM, covariance and mean are linear in 'dt'
    newX <- x0*exp( rmvnorm(nrow(x0), sig=sigm*dt, 
                            mean= (model$r- model$div- model$sigma^2/2)*dt) )

    return (newX)
}
```

Next, we construct the problem instance, i.e. the model in mlOSP parlance.

```{r}
modelBecker <- list(dim=5,sigma=0.08*(1:5), r= 0.05, div=0.1, rho=0, 
                    x0 = rep(90,5), T=3, K=100, dt=1/3, sim.func=sim.corGBM, km.upper=rep(100,5))
```

For the design we consider a union of a space-filling design on $[50,200]^d$ of size 400 and a probabilistic design of size 200. We are now ready to test with a *hetGP* metamodel which requires a few more parameter specification


```{r becker-fit}
sf400 <- 50 + 150*randtoolbox::sobol(400,d=5, scrambl=1)
pd200 <- sim.corGBM( matrix(rep(modelBecker$x0,200), nrow=200,byrow=T), 
                     modelBecker, modelBecker$T)
option.payoff <- maxCall
modelBecker$km.batch <= 50
modelBecker$covtype <- "Matern5_2"
modelBecker$pilot.nsims <- 100
modelBecker$N <- 600
modelBecker$look.ahead <- 1

beckerFit <- osp.fixed.design(modelBecker,input.dom=rbind(sf400,pd200), method="hetgp")
```
We finally test on an out-of-sample set of scenarios.
```{r becker-test}
NN <- 100000
MM <- 9
set.seed(102)
test.Becker <- list()
test.Becker[[1]] <- modelBecker$sim.func( matrix(rep(modelBecker$x0, NN), nrow=NN, byrow=T), 
                                          modelBecker, modelBecker$dt)
for (i in 2:MM)
   test.Becker[[i]] <- modelBecker$sim.func( test.Becker[[i-1]], modelBecker, modelBecker$dt)
# sanity check: European option value
print(mean( exp(-modelBecker$r*modelBecker$T)*option.payoff(K=100,test.Becker[[MM]])))
oos <- forward.sim.policy( test.Becker, MM, beckerFit$fit, modelBecker)$payoff
print( c(mean(oos) - 1.96*sd(oos)/sqrt(NN), mean(oos)+1.96*sd(oos)/sqrt(NN)) )

```
Voila. This can be compared against the reported interval of [27.63, 27.69]. We note the very high standard deviation of realized payoffs which leads to a wide credible interval of the final answer. Thus, obtaining tight bounds requires a very large out-of-sample test set. 

## References

```{r longstaff-schwartz-base}
set.seed(262)
lsModel <- list()
x0 <- 40; lsModel$dim <-1; lsModel$r <- 0.05; lsModel$sigma <- 0.2; lsModel$div <- 0
lsModel$dt <- 0.1

Np <- 20; Nt <- 5
paths[[1]] <- sim.gbm( matrix(rep(x0, Np), nrow=Np,byrow=T), lsModel, lsModel$dt)
for (j in 2:(Nt+1))
    paths[[j]] <- sim.gbm( paths[[j-1]], lsModel, lsModel$dt)
plot(paths[[4]], pmax(40-paths[[5]],0),xlim=c(29,54), xlab="S_t", ylab="Continuation Value", 
     pch=19, cex=1.4, cex.lab=1.2, cex.axis=1.2, bty="n")
rmc <- list()
payoff <- list()
payoff[[4]] <- pmax(40-paths[[5]],0)
rmc[[4]] <- lm(y ~ poly(x,2), data.frame(y= payoff[[4]], x = paths[[4]]))
coef(rmc[[4]])
testx <- seq(28,55,len=50); 
predy <- predict.lm(rmc[[4]], new=data.frame(x=testx))
lines(testx, predy, lwd=4, col="lightblue")

ggplot(data.frame(y= payoff[[4]], x = paths[[4]]), aes(x, y)) + geom_point(size=3) + theme_light() +
       geom_smooth(method="lm", formula=y~poly(x, 2), size=2) + labs(subtitle=paste( round(coef(rmc[[4]])[1],3), round(coef(rmc[[4]])[2],3),"x+", round(coef(rmc[[4]])[3],3), "x^2"))
```
```{r}
# Show the immediate payoff and predicted cont
# kable(data.frame(x=paths[[4]], y=payoff[[4]]*exp(-lsModel$r*lsModel$dt), pred=rmc[[4]]$fitted.values*exp(-lsModel$r*lsModel$dt), cur=pmax(40-paths[[4]],0)), format="markdown")
plot(testx, pmax(40-testx, 0),lwd=3, col="red", xlab="S", ylab="Cont Value", cex.lab=1.3,type="l")
lines(testx, exp(-lsModel$r*lsModel$dt)*predy, lwd=3, lty=2, col="blue")
lines(testx, pmax(exp(-lsModel$r*lsModel$dt)*predy,0 ), lwd=3, col="blue")
find_stopBnd <- function(guessx, obj, disc) {
  predy <- predict.lm(obj, new=data.frame(x=guessx))*disc - (40-guessx)
  return(predy)
}
stopBnd <- array(0, dim=c(4,1))
stopBnd[4] <- uniroot(find_stopBnd, c(33,40), rmc[[4]], exp(-lsModel$r*lsModel$dt))$root
lines(c(stopBnd[k], 55), c(-0.4, -0.4), col="green", lwd=5)
```


```{r ls-full-loop}
testx <- seq(28,55,len=50); 
payoff[[4]] <- pmax(40-paths[[5]],0)
par(mfrow=c(3,2))
for (k in 4:2) {
  
  rmc[[k]] <- lm(y ~ poly(x,2), data.frame(y= payoff[[k]], x = paths[[k]]))
  plot(paths[[k]], payoff[[k]],xlim=c(29,54), xlab="S_t", ylab="Continuation Value", 
     pch=19, cex=1.4, cex.lab=1.2, cex.axis=1.2, bty="n", main=paste("k=", k," with fit ", 
          round(coef(rmc[[k]])[1],3), round(coef(rmc[[k]])[2],3),"x+", round(coef(rmc[[k]])[3],3), "x^2"))
  
  #coef(rmc[[k]])
  predy <- predict.lm(rmc[[k]], new=data.frame(x=testx))
  lines(testx, predy, lwd=4, col="lightblue")
  plot(testx, pmax(40-testx, 0),lwd=3, col="red", xlab="S", ylab="Cont Value", cex.lab=1.3,type="l")
  lines(testx, pmax(exp(-lsModel$r*lsModel$dt)*predy,0 ), lwd=3, col="blue")
  #stopBnd[k] <- uniroot(find_stopBnd, c(30,40), rmc[[k]], exp(-lsModel$r*lsModel$dt))$root
  #lines(c(stopBnd[k], 55), c(-0.4, -0.4), col="green", lwd=5)
  payoff[[k-1]] <- pmax(exp(-lsModel$r*lsModel$dt)*rmc[[k]]$fitted.values, 40-paths[[k]], 0 )
}
mean(payoff[[1]])*exp(-lsModel$r*lsModel$dt)


```